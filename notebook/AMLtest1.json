{
	"name": "AMLtest1",
	"properties": {
		"folder": {
			"name": "AzureML"
		},
		"nbformat": 4,
		"nbformat_minor": 2,
		"bigDataPool": {
			"referenceName": "accsparkpools",
			"type": "BigDataPoolReference"
		},
		"sessionProperties": {
			"driverMemory": "112g",
			"driverCores": 16,
			"executorMemory": "112g",
			"executorCores": 16,
			"numExecutors": 2,
			"conf": {
				"spark.dynamicAllocation.enabled": "false",
				"spark.dynamicAllocation.minExecutors": "2",
				"spark.dynamicAllocation.maxExecutors": "2"
			}
		},
		"metadata": {
			"saveOutput": true,
			"kernelspec": {
				"name": "synapse_pyspark",
				"display_name": "Synapse PySpark"
			},
			"language_info": {
				"name": "python"
			},
			"a365ComputeOptions": {
				"id": "/subscriptions/c46a9435-c957-4e6c-a0f4-b9a597984773/resourceGroups/accenture/providers/Microsoft.Synapse/workspaces/bbaccsynapse/bigDataPools/accsparkpools",
				"name": "accsparkpools",
				"type": "Spark",
				"endpoint": "https://bbaccsynapse.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/accsparkpools",
				"auth": {
					"type": "AAD",
					"authResource": "https://dev.azuresynapse.net"
				},
				"sparkVersion": "2.4",
				"nodeCount": 10,
				"cores": 16,
				"memory": 112
			}
		},
		"cells": [
			{
				"cell_type": "code",
				"source": [
					"blob_account_name = \"azureopendatastorage\"\n",
					"blob_container_name = \"nyctlc\"\n",
					"blob_relative_path = \"yellow\"\n",
					"blob_sas_token = r\"\""
				],
				"execution_count": 1
			},
			{
				"cell_type": "code",
				"source": [
					"# Allow Spark to read from Blob remotely\n",
					"wasbs_path = 'wasbs://%s@%s.blob.core.windows.net/%s' % (blob_container_name, blob_account_name, blob_relative_path)\n",
					"spark.conf.set('fs.azure.sas.%s.%s.blob.core.windows.net' % (blob_container_name, blob_account_name),blob_sas_token)\n",
					"\n",
					"# Spark read parquet, note that it won't load any data yet by now\n",
					"df = spark.read.parquet(wasbs_path)"
				],
				"execution_count": 2
			},
			{
				"cell_type": "code",
				"source": [
					"# Create an ingestion filter\n",
					"start_date = '2015-01-01 00:00:00'\n",
					"end_date = '2015-12-31 00:00:00'\n",
					"\n",
					"filtered_df = df.filter('tpepPickupDateTime > \"' + start_date + '\" and tpepPickupDateTime < \"' + end_date + '\"')\n",
					"\n",
					"filtered_df.describe().show()"
				],
				"execution_count": 3
			},
			{
				"cell_type": "code",
				"source": [
					"from datetime import datetime\n",
					"from pyspark.sql.functions import *\n",
					"\n",
					"# To make development easier, faster and less expensive down sample for now\n",
					"sampled_taxi_df = filtered_df.sample(True, 0.001, seed=1234)\n",
					"\n",
					"taxi_df = sampled_taxi_df.select('vendorID', 'passengerCount', 'tripDistance',  'startLon', 'startLat', 'endLon' \\\n",
					"                                , 'endLat', 'paymentType', 'fareAmount', 'tipAmount'\\\n",
					"                                , column('puMonth').alias('month_num') \\\n",
					"                                , date_format('tpepPickupDateTime', 'hh').alias('hour_of_day')\\\n",
					"                                , date_format('tpepPickupDateTime', 'EEEE').alias('day_of_week')\\\n",
					"                                , dayofmonth(col('tpepPickupDateTime')).alias('day_of_month')\n",
					"                                ,(unix_timestamp(col('tpepDropoffDateTime')) - unix_timestamp(col('tpepPickupDateTime'))).alias('trip_time'))\\\n",
					"                        .filter((sampled_taxi_df.passengerCount > 0) & (sampled_taxi_df.passengerCount < 8)\\\n",
					"                                & (sampled_taxi_df.tipAmount >= 0)\\\n",
					"                                & (sampled_taxi_df.fareAmount >= 1) & (sampled_taxi_df.fareAmount <= 250)\\\n",
					"                                & (sampled_taxi_df.tipAmount < sampled_taxi_df.fareAmount)\\\n",
					"                                & (sampled_taxi_df.tripDistance > 0) & (sampled_taxi_df.tripDistance <= 200)\\\n",
					"                                & (sampled_taxi_df.rateCodeId <= 5)\\\n",
					"                                & (sampled_taxi_df.paymentType.isin({\"1\", \"2\"})))\n",
					"taxi_df.show(10)"
				],
				"execution_count": 4
			},
			{
				"cell_type": "code",
				"source": [
					"# Random split dataset using spark, convert Spark to Pandas\n",
					"training_data, validation_data = taxi_df.randomSplit([0.8,0.2], 223)"
				],
				"execution_count": 5
			},
			{
				"cell_type": "code",
				"source": [
					"from azureml.core import Workspace\n",
					"\n",
					"# Enter your workspace subscription, resource group, name, and region.\n",
					"subscription_id = \"c46a9435-c957-4e6c-a0f4-b9a597984773\" #you should be owner or contributor\n",
					"resource_group = \"mlops\" #you should be owner or contributor\n",
					"workspace_name = \"mlopsdev\" #your workspace name\n",
					"#workspace_region = \"<enter workspace region>\" #your region\n",
					"\n",
					"ws = Workspace(workspace_name = workspace_name,\n",
					"               subscription_id = subscription_id,\n",
					"               resource_group = resource_group)"
				],
				"execution_count": 6
			},
			{
				"cell_type": "code",
				"source": [
					"import pandas \n",
					"from azureml.core import Dataset\n",
					"\n",
					"# Get the AML Default Datastore\n",
					"datastore = ws.get_default_datastore()\n",
					"training_pd = training_data.toPandas().to_csv('training_pd.csv', index=False)\n",
					"\n",
					"# Convert into AML Tabular Dataset\n",
					"datastore.upload_files(files = ['training_pd.csv'],\n",
					"                       target_path = 'train-dataset/tabular/',\n",
					"                       overwrite = True,\n",
					"                       show_progress = True)\n",
					"dataset_training = Dataset.Tabular.from_delimited_files(path = [(datastore, 'train-dataset/tabular/training_pd.csv')])"
				],
				"execution_count": 7
			},
			{
				"cell_type": "code",
				"source": [
					"import logging\n",
					"\n",
					"automl_settings = {\n",
					"    \"iteration_timeout_minutes\": 10,\n",
					"    \"experiment_timeout_minutes\": 30,\n",
					"    \"enable_early_stopping\": True,\n",
					"    \"primary_metric\": 'r2_score',\n",
					"    \"featurization\": 'auto',\n",
					"    \"verbosity\": logging.INFO,\n",
					"    \"n_cross_validations\": 2}"
				],
				"execution_count": 8
			},
			{
				"cell_type": "code",
				"source": [
					"from azureml.train.automl import AutoMLConfig\n",
					"\n",
					"automl_config = AutoMLConfig(task='regression',\n",
					"                             debug_log='automated_ml_errors.log',\n",
					"                             training_data = dataset_training,\n",
					"                             spark_context = sc,\n",
					"                             model_explainability = False, \n",
					"                             label_column_name =\"fareAmount\",**automl_settings)"
				],
				"execution_count": 9
			},
			{
				"cell_type": "code",
				"source": [
					"from azureml.core.experiment import Experiment\n",
					"\n",
					"# Start an experiment in Azure Machine Learning\n",
					"experiment = Experiment(ws, \"aml-synapse-regression\")\n",
					"tags = {\"Synapse\": \"regression\"}\n",
					"local_run = experiment.submit(automl_config, show_output=True, tags = tags)\n",
					"\n",
					"# Use the get_details function to retrieve the detailed output for the run.\n",
					"run_details = local_run.get_details()"
				],
				"execution_count": 10
			},
			{
				"cell_type": "code",
				"source": [
					"# Get best model\n",
					"best_run, fitted_model = local_run.get_output()"
				],
				"execution_count": 11
			},
			{
				"cell_type": "code",
				"source": [
					"# Test best model accuracy\n",
					"validation_data_pd = validation_data.toPandas()\n",
					"y_test = validation_data_pd.pop(\"fareAmount\").to_frame()\n",
					"y_predict = fitted_model.predict(validation_data_pd)"
				],
				"execution_count": 12
			},
			{
				"cell_type": "code",
				"source": [
					"from sklearn.metrics import mean_squared_error\n",
					"from math import sqrt\n",
					"\n",
					"# Calculate Root Mean Square Error\n",
					"y_actual = y_test.values.flatten().tolist()\n",
					"rmse = sqrt(mean_squared_error(y_actual, y_predict))\n",
					"\n",
					"print(\"Root Mean Square Error:\")\n",
					"print(rmse)"
				],
				"execution_count": 13
			},
			{
				"cell_type": "code",
				"source": [
					"# Calculate MAPE and Model Accuracy \n",
					"sum_actuals = sum_errors = 0\n",
					"\n",
					"for actual_val, predict_val in zip(y_actual, y_predict):\n",
					"    abs_error = actual_val - predict_val\n",
					"    if abs_error < 0:\n",
					"        abs_error = abs_error * -1\n",
					"\n",
					"    sum_errors = sum_errors + abs_error\n",
					"    sum_actuals = sum_actuals + actual_val\n",
					"\n",
					"mean_abs_percent_error = sum_errors / sum_actuals\n",
					"\n",
					"print(\"Model MAPE:\")\n",
					"print(mean_abs_percent_error)\n",
					"print()\n",
					"print(\"Model Accuracy:\")\n",
					"print(1 - mean_abs_percent_error)"
				],
				"execution_count": 14
			},
			{
				"cell_type": "code",
				"source": [
					"import matplotlib.pyplot as plt\n",
					"import numpy as np\n",
					"from sklearn.metrics import mean_squared_error, r2_score\n",
					"\n",
					"# Calculate the R2 score using the predicted and actual fare prices\n",
					"y_test_actual = y_test[\"fareAmount\"]\n",
					"r2 = r2_score(y_test_actual, y_predict)\n",
					"\n",
					"# Plot the Actual vs Predicted Fare Amount Values\n",
					"plt.style.use('ggplot')\n",
					"plt.figure(figsize=(10, 7))\n",
					"plt.scatter(y_test_actual,y_predict)\n",
					"plt.plot([np.min(y_test_actual), np.max(y_test_actual)], [np.min(y_test_actual), np.max(y_test_actual)], color='lightblue')\n",
					"plt.xlabel(\"Actual Fare Amount\")\n",
					"plt.ylabel(\"Predicted Fare Amount\")\n",
					"plt.title(\"Actual vs Predicted Fare Amont R^2={}\".format(r2))\n",
					"plt.show()"
				],
				"execution_count": 15
			},
			{
				"cell_type": "code",
				"source": [
					"description = 'My AutoML Model'\n",
					"model_path='outputs/model.pkl'\n",
					"model = best_run.register_model(model_name = 'NYCGreenTaxiModel', model_path = model_path, description = description)\n",
					"print(model.name, model.version)"
				],
				"execution_count": 16
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			},
			{
				"cell_type": "code",
				"source": [
					""
				],
				"execution_count": null
			}
		]
	}
}